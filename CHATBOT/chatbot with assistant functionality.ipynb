{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import speech_recognition as sr\n",
    "warnings.filterwarnings('ignore')\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "import pyttsx3\n",
    "from gtts import gTTS\n",
    "import os\n",
    "from playsound import playsound  \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic = sr.Microphone(device_index=1)\n",
    "engine = pyttsx3.init()\n",
    "engine.setProperty(\"rate\", 160)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_audio():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=0.2)\n",
    "        audio = recognizer.listen(source)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_text(audio_data):\n",
    "    recognizer = sr.Recognizer()\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio_data)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sorry, I could not understand what you said.\")\n",
    "        return \"\"\n",
    "    except sr.RequestError:\n",
    "        print(\"There was an error connecting to the Google Speech Recognition API.\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qa_model = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "language = 'en'\n",
    "GREET_INPUTS = [\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\"]\n",
    "GREET_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:\\CODING\\chatbot\\chatbot dataset.txt\"\n",
    "with open(path, 'r') as f:\n",
    "  filedata = f.read()\n",
    "  context = filedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "You said: what are you doing\n",
      "['what', 'are', 'you', 'doing']\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "You said: good thought about you I am not good\n",
      "['good', 'thought', 'about', 'you', 'i', 'am', 'not', 'good']\n",
      "Listening...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m     text_output \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m     audio_data \u001b[39m=\u001b[39m capture_audio()\n\u001b[0;32m      4\u001b[0m     text_output \u001b[39m=\u001b[39m audio_to_text(audio_data)\n\u001b[0;32m      5\u001b[0m     \u001b[39mif\u001b[39;00m  text_output \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "Cell \u001b[1;32mIn[41], line 6\u001b[0m, in \u001b[0;36mcapture_audio\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mListening...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m     recognizer\u001b[39m.\u001b[39madjust_for_ambient_noise(source, duration\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     audio \u001b[39m=\u001b[39m recognizer\u001b[39m.\u001b[39;49mlisten(source)\n\u001b[0;32m      7\u001b[0m \u001b[39mreturn\u001b[39;00m audio\n",
      "File \u001b[1;32mc:\\Users\\Akshay\\anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py:523\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[39mif\u001b[39;00m phrase_time_limit \u001b[39mand\u001b[39;00m elapsed_time \u001b[39m-\u001b[39m phrase_start_time \u001b[39m>\u001b[39m phrase_time_limit:\n\u001b[0;32m    521\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 523\u001b[0m buffer \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mread(source\u001b[39m.\u001b[39;49mCHUNK)\n\u001b[0;32m    524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(buffer) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39mbreak\u001b[39;00m  \u001b[39m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    525\u001b[0m frames\u001b[39m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32mc:\\Users\\Akshay\\anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py:199\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, size):\n\u001b[1;32m--> 199\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpyaudio_stream\u001b[39m.\u001b[39;49mread(size, exception_on_overflow\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNot input stream\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[39mreturn\u001b[39;00m pa\u001b[39m.\u001b[39;49mread_stream(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stream, num_frames,\n\u001b[0;32m    571\u001b[0m                       exception_on_overflow)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# while True:\n",
    "#     text_output = \"\"\n",
    "#     audio_data = capture_audio()\n",
    "#     text_output = audio_to_text(audio_data)\n",
    "#     if  text_output != \"\":\n",
    "#         print(\"You said:\", text_output)\n",
    "#         question = text_output.lower()\n",
    "#         splitted = question.split()\n",
    "#         print(splitted)\n",
    "#         # for word in splitted:\n",
    "#         #     if word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "You said: hello\n",
      "Model predicted\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "You said: hello Shiva\n",
      "Model predicted\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "You said: Rai\n",
      "Model predicted\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "You said: braining\n",
      "Model predicted\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "You said: Alexa\n",
      "Model predicted\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "You said: he is raining\n",
      "Model predicted\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "You said: hello magn\n",
      "Model predicted\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "You said: hello Nexus\n",
      "Model predicted\n",
      "Listening...\n",
      "You said: Nexus\n",
      "Model predicted\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "You said: tell me something about Nexus\n",
      "Model predicted\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n",
      "Sorry, I could not understand what you said.\n",
      "Listening...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m      3\u001b[0m     text_output \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m     audio_data \u001b[39m=\u001b[39m capture_audio()\n\u001b[0;32m      5\u001b[0m     text_output \u001b[39m=\u001b[39m audio_to_text(audio_data)\n\u001b[0;32m      6\u001b[0m     \u001b[39mif\u001b[39;00m  text_output \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "Cell \u001b[1;32mIn[41], line 5\u001b[0m, in \u001b[0;36mcapture_audio\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mwith\u001b[39;00m sr\u001b[39m.\u001b[39mMicrophone() \u001b[39mas\u001b[39;00m source:\n\u001b[0;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mListening...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     recognizer\u001b[39m.\u001b[39;49madjust_for_ambient_noise(source, duration\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m     audio \u001b[39m=\u001b[39m recognizer\u001b[39m.\u001b[39mlisten(source)\n\u001b[0;32m      7\u001b[0m \u001b[39mreturn\u001b[39;00m audio\n",
      "File \u001b[1;32mc:\\Users\\Akshay\\anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py:393\u001b[0m, in \u001b[0;36mRecognizer.adjust_for_ambient_noise\u001b[1;34m(self, source, duration)\u001b[0m\n\u001b[0;32m    391\u001b[0m elapsed_time \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m seconds_per_buffer\n\u001b[0;32m    392\u001b[0m \u001b[39mif\u001b[39;00m elapsed_time \u001b[39m>\u001b[39m duration: \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m buffer \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mread(source\u001b[39m.\u001b[39;49mCHUNK)\n\u001b[0;32m    394\u001b[0m energy \u001b[39m=\u001b[39m audioop\u001b[39m.\u001b[39mrms(buffer, source\u001b[39m.\u001b[39mSAMPLE_WIDTH)  \u001b[39m# energy of the audio signal\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[39m# dynamically adjust the energy threshold using asymmetric weighted average\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Akshay\\anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py:199\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, size):\n\u001b[1;32m--> 199\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpyaudio_stream\u001b[39m.\u001b[39;49mread(size, exception_on_overflow\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNot input stream\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[39mreturn\u001b[39;00m pa\u001b[39m.\u001b[39;49mread_stream(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stream, num_frames,\n\u001b[0;32m    571\u001b[0m                       exception_on_overflow)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "temp = 0\n",
    "while True:\n",
    "    text_output = \"\"\n",
    "    audio_data = capture_audio()\n",
    "    text_output = audio_to_text(audio_data)\n",
    "    if  text_output != \"\":\n",
    "        print(\"You said:\", text_output)\n",
    "        question = text_output\n",
    "        splitted = question.split()\n",
    "        \n",
    "        for word in splitted:\n",
    "            if word in GREET_INPUTS:\n",
    "                mytext = random.choice(GREET_RESPONSES)\n",
    "                engine.say(mytext)\n",
    "                engine.runAndWait()\n",
    "                temp = 1\n",
    "                break\n",
    "        else:\n",
    "            if temp == 1:\n",
    "                pass\n",
    "            else:    \n",
    "                print(\"word not found\")\n",
    "            \n",
    "        # engine.say(mytext)\n",
    "        # engine.runAndWait()\n",
    "        # print(\"Model predicted: \",answer['answer'], end='\\n')    \n",
    "        print(\"Model predicted\")\n",
    "\n",
    "\n",
    "\n",
    "        # answer = qa_model(question = question, context = context)\n",
    "        # mytext = answer['answer']\n",
    "        # engine.say(mytext)\n",
    "        # engine.runAndWait()\n",
    "        # print(\"Model predicted: \",answer['answer'], end='\\n')\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
